{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52886b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875c0dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\macro-estimator\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\envs\\macro-estimator\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using device: cuda ---\n",
      "Loading model 'vit_base_patch16_224.augreg_in21k' to get data configuration...\n",
      "Initializing dataset...\n",
      "Data loaded: 22788 training samples, 5696 validation samples.\n",
      "--- Starting training from scratch ---\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\macro-estimator\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training... Batch 357/357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\macro-estimator\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Epoch 1 Summary:\n",
      "  - Avg. Training Loss (MSE): 1230.8729\n",
      "  - Avg. Validation Loss (MSE): 1588.6022\n",
      "  - Avg. Validation MAE: 12.44 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1588.6022)\n",
      "\n",
      "Epoch 2/100\n",
      "âœ“ Epoch 2 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1107.7160\n",
      "  - Avg. Validation Loss (MSE): 1512.1928\n",
      "  - Avg. Validation MAE: 11.95 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1512.1928)\n",
      "\n",
      "Epoch 3/100\n",
      "âœ“ Epoch 3 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1066.9253\n",
      "  - Avg. Validation Loss (MSE): 1485.9361\n",
      "  - Avg. Validation MAE: 11.95 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1485.9361)\n",
      "\n",
      "Epoch 4/100\n",
      "âœ“ Epoch 4 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1047.4953\n",
      "  - Avg. Validation Loss (MSE): 1470.0939\n",
      "  - Avg. Validation MAE: 11.67 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1470.0939)\n",
      "\n",
      "Epoch 5/100\n",
      "âœ“ Epoch 5 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1033.7737\n",
      "  - Avg. Validation Loss (MSE): 1457.0270\n",
      "  - Avg. Validation MAE: 11.32 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1457.0270)\n",
      "\n",
      "Epoch 6/100\n",
      "âœ“ Epoch 6 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1022.0850\n",
      "  - Avg. Validation Loss (MSE): 1445.6029\n",
      "  - Avg. Validation MAE: 11.00 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1445.6029)\n",
      "\n",
      "Epoch 7/100\n",
      "âœ“ Epoch 7 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1011.6139\n",
      "  - Avg. Validation Loss (MSE): 1435.2847\n",
      "  - Avg. Validation MAE: 10.79 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1435.2847)\n",
      "\n",
      "Epoch 8/100\n",
      "âœ“ Epoch 8 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 1002.8547\n",
      "  - Avg. Validation Loss (MSE): 1426.3455\n",
      "  - Avg. Validation MAE: 10.52 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1426.3455)\n",
      "\n",
      "Epoch 9/100\n",
      "âœ“ Epoch 9 Summary:h 357/357\n",
      "  - Avg. Training Loss (MSE): 995.0167\n",
      "  - Avg. Validation Loss (MSE): 1418.4568\n",
      "  - Avg. Validation MAE: 10.27 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1418.4568)\n",
      "\n",
      "Epoch 10/100\n",
      "âœ“ Epoch 10 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 988.2297\n",
      "  - Avg. Validation Loss (MSE): 1411.1488\n",
      "  - Avg. Validation MAE: 10.09 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1411.1488)\n",
      "\n",
      "Epoch 11/100\n",
      "âœ“ Epoch 11 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 983.2644\n",
      "  - Avg. Validation Loss (MSE): 1404.6183\n",
      "  - Avg. Validation MAE: 9.93 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1404.6183)\n",
      "\n",
      "Epoch 12/100\n",
      "âœ“ Epoch 12 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 977.9592\n",
      "  - Avg. Validation Loss (MSE): 1398.5477\n",
      "  - Avg. Validation MAE: 9.75 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1398.5477)\n",
      "\n",
      "Epoch 13/100\n",
      "âœ“ Epoch 13 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 971.8049\n",
      "  - Avg. Validation Loss (MSE): 1392.6641\n",
      "  - Avg. Validation MAE: 9.68 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1392.6641)\n",
      "\n",
      "Epoch 14/100\n",
      "âœ“ Epoch 14 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 967.1641\n",
      "  - Avg. Validation Loss (MSE): 1387.7800\n",
      "  - Avg. Validation MAE: 9.55 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1387.7800)\n",
      "\n",
      "Epoch 15/100\n",
      "âœ“ Epoch 15 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 963.1169\n",
      "  - Avg. Validation Loss (MSE): 1382.9741\n",
      "  - Avg. Validation MAE: 9.49 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1382.9741)\n",
      "\n",
      "Epoch 16/100\n",
      "âœ“ Epoch 16 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 960.2495\n",
      "  - Avg. Validation Loss (MSE): 1378.3067\n",
      "  - Avg. Validation MAE: 9.49 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1378.3067)\n",
      "\n",
      "Epoch 17/100\n",
      "âœ“ Epoch 17 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 1110.8626\n",
      "  - Avg. Validation Loss (MSE): 1374.3193\n",
      "  - Avg. Validation MAE: 9.40 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1374.3193)\n",
      "\n",
      "Epoch 18/100\n",
      "âœ“ Epoch 18 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 954.8046\n",
      "  - Avg. Validation Loss (MSE): 1370.9301\n",
      "  - Avg. Validation MAE: 9.38 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1370.9301)\n",
      "\n",
      "Epoch 19/100\n",
      "âœ“ Epoch 19 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 950.6643\n",
      "  - Avg. Validation Loss (MSE): 1368.1522\n",
      "  - Avg. Validation MAE: 9.30 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1368.1522)\n",
      "\n",
      "Epoch 20/100\n",
      "âœ“ Epoch 20 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 948.7413\n",
      "  - Avg. Validation Loss (MSE): 1365.0784\n",
      "  - Avg. Validation MAE: 9.31 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1365.0784)\n",
      "\n",
      "Epoch 21/100\n",
      "âœ“ Epoch 21 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 946.1570\n",
      "  - Avg. Validation Loss (MSE): 1362.1663\n",
      "  - Avg. Validation MAE: 9.32 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1362.1663)\n",
      "\n",
      "Epoch 22/100\n",
      "âœ“ Epoch 22 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 943.9720\n",
      "  - Avg. Validation Loss (MSE): 1359.6380\n",
      "  - Avg. Validation MAE: 9.28 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1359.6380)\n",
      "\n",
      "Epoch 23/100\n",
      "âœ“ Epoch 23 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 942.0811\n",
      "  - Avg. Validation Loss (MSE): 1356.9143\n",
      "  - Avg. Validation MAE: 9.25 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1356.9143)\n",
      "\n",
      "Epoch 24/100\n",
      "âœ“ Epoch 24 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 939.9180\n",
      "  - Avg. Validation Loss (MSE): 1353.8690\n",
      "  - Avg. Validation MAE: 9.36 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1353.8690)\n",
      "\n",
      "Epoch 25/100\n",
      "âœ“ Epoch 25 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 938.1277\n",
      "  - Avg. Validation Loss (MSE): 1352.2118\n",
      "  - Avg. Validation MAE: 9.20 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1352.2118)\n",
      "\n",
      "Epoch 26/100\n",
      "âœ“ Epoch 26 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 936.4104\n",
      "  - Avg. Validation Loss (MSE): 1349.3368\n",
      "  - Avg. Validation MAE: 9.28 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1349.3368)\n",
      "\n",
      "Epoch 27/100\n",
      "âœ“ Epoch 27 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 934.6352\n",
      "  - Avg. Validation Loss (MSE): 1346.8535\n",
      "  - Avg. Validation MAE: 9.35 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1346.8535)\n",
      "\n",
      "Epoch 28/100\n",
      "âœ“ Epoch 28 Summary: 357/357\n",
      "  - Avg. Training Loss (MSE): 933.1506\n",
      "  - Avg. Validation Loss (MSE): 1344.9799\n",
      "  - Avg. Validation MAE: 9.27 (avg. error per nutrient)\n",
      "  -> ðŸŽ‰ New best model checkpoint saved to artifacts\\models\\vit_nutrition_regressor.pth (Val Loss: 1344.9799)\n",
      "\n",
      "Epoch 29/100\n",
      "  Training... Batch 178/357"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 158\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Training Finished ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest model saved at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_SAVE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with a final validation MSE of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    108\u001b[39m     loss.backward()\n\u001b[32m    109\u001b[39m     optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     running_train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m  Training... Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# --- Validation Phase ---\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script fine-tunes a Vision Transformer (ViT-B/16) pre-trained on ImageNet-21k\n",
    "for a regression task: predicting nutritional values from an image of a dish.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Any\n",
    "import timm\n",
    "\n",
    "from src.macro_estimator.models.vit_regressor import ViTRegressor\n",
    "from src.macro_estimator.datasets import Nutrition5kDataset\n",
    "# --- 1. Configuration and Constants ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Data Paths ---\n",
    "IMAGES_CSV_PATH = Path(\"data/csv_files/images.csv\")\n",
    "LABELS_CSV_PATH = Path(\"data/csv_files/labels.csv\")\n",
    "MODEL_SAVE_PATH = Path(\"artifacts/models/vit_nutrition_regressor.pth\")\n",
    "RESUME_CHECKPOINT_PATH = \"artifacts/models/vit_nutrition_regressor.pth\"\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64  # Adjust based on your GPU memory\n",
    "EPOCHS = 100      # Fine-tuning might require more epochs\n",
    "WEIGHT_DECAY = 1e-4\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# --- The updated main function ---\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the model training and validation process.\n",
    "    Supports resuming training from a saved checkpoint.\n",
    "    \"\"\"\n",
    "    print(f\"--- Using device: {DEVICE} ---\")\n",
    "\n",
    "    # --- Data Loading and Transformations ---\n",
    "    MODEL_NAME = 'vit_base_patch16_224.augreg_in21k'\n",
    "    \n",
    "    # ... (Data loading and transforms code remains exactly the same) ...\n",
    "    print(f\"Loading model '{MODEL_NAME}' to get data configuration...\")\n",
    "    temp_model = timm.create_model(MODEL_NAME, pretrained=True)\n",
    "    data_config = timm.data.resolve_data_config(model=temp_model)\n",
    "    transforms = timm.data.create_transform(**data_config)\n",
    "    del temp_model\n",
    "\n",
    "    print(\"Initializing dataset...\")\n",
    "    full_dataset = Nutrition5kDataset(\n",
    "        images_csv_path=IMAGES_CSV_PATH,\n",
    "        labels_csv_path=LABELS_CSV_PATH,\n",
    "        transform=transforms\n",
    "    )\n",
    "    # ... (Dataset split and DataLoader creation remains the same) ...\n",
    "    val_size = int(len(full_dataset) * VAL_SPLIT)\n",
    "    train_size = len(full_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    print(f\"Data loaded: {train_size} training samples, {val_size} validation samples.\")\n",
    "\n",
    "\n",
    "    # --- Model, Loss, and Optimizer ---\n",
    "    model = ViTRegressor(model_name=MODEL_NAME, n_outputs=4).to(DEVICE)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # --- NEW: LOGIC TO LOAD CHECKPOINT ---\n",
    "    if RESUME_CHECKPOINT_PATH and Path(RESUME_CHECKPOINT_PATH).exists():\n",
    "        print(f\"--- Resuming training from checkpoint: {RESUME_CHECKPOINT_PATH} ---\")\n",
    "        \n",
    "        # It's good practice to load checkpoint on CPU first, then move model to device\n",
    "        checkpoint = torch.load(RESUME_CHECKPOINT_PATH, map_location='cpu')\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1 # Start from the next epoch\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf')) # Use .get for backward compatibility\n",
    "        \n",
    "        print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}.\")\n",
    "        print(f\"Previous best validation loss was {best_val_loss:.4f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"--- Starting training from scratch ---\")\n",
    "   \n",
    "    for epoch in range(EPOCHS):\n",
    "        # --- Training Phase ---\n",
    "        model.train() # Set the model to training mode\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        # Using a simple progress indicator for the training loop\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            print(f\"\\r  Training... Batch {i+1}/{len(train_loader)}\", end=\"\")\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "        running_val_mae = 0.0 # Mean Absolute Error for better interpretation\n",
    "        \n",
    "        with torch.no_grad(): # Disable gradient calculation for validation\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                running_val_mae += torch.abs(outputs - labels).sum().item()\n",
    "\n",
    "        # --- Epoch Summary and Saving Logic ---\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        \n",
    "        # Total number of individual predictions = (number of samples) * (number of outputs)\n",
    "        total_predictions = len(val_dataset) * 4 \n",
    "        avg_val_mae = running_val_mae / total_predictions\n",
    "\n",
    "        print(f\"\\râœ“ Epoch {epoch+1} Summary:\")\n",
    "        print(f\"  - Avg. Training Loss (MSE): {avg_train_loss:.4f}\")\n",
    "        print(f\"  - Avg. Validation Loss (MSE): {avg_val_loss:.4f}\")\n",
    "        print(f\"  - Avg. Validation MAE: {avg_val_mae:.2f} (avg. error per nutrient)\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            MODEL_SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Create a dictionary to save all necessary states\n",
    "            checkpoint_data = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint_data, MODEL_SAVE_PATH)\n",
    "            print(f\"  -> ðŸŽ‰ New best model checkpoint saved to {MODEL_SAVE_PATH} (Val Loss: {best_val_loss:.4f})\")\n",
    "\n",
    "    print(\"\\n--- Training Finished ---\")\n",
    "    print(f\"Best model saved at {MODEL_SAVE_PATH} with a final validation MSE of {best_val_loss:.4f}\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab9b0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/csv_files/images.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config/config.yaml')\n",
    "\n",
    "config['data_paths']['images_csv']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macro-estimator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
